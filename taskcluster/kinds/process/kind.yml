transforms:
  - local_taskgraph.date_tasks

task-defaults:
  run-on-git-branches:
    - main
  worker-type: b-linux
  worker:
    # Because all tasks rely on the ingester tasks right now, we just use the
    # same image for everything.
    docker-image: {in-tree: ingester}
    max-run-time: 3600 # 1 hour

tasks:
  pings:
    name: process-pings
    description: "Process a particular day's crash ping data and upload to bigquery."
    # Ingest symbolication can take advantage of a lot of CPU (and disk space).
    worker-type: t-linux-large
    worker:
      # These tasks should take under an hour, however just in case we will
      # give more run time.
      max-run-time: 14400 # 4 hours
    attributes:
      artifact_prefix: "public"
    scopes:
      - secrets:get:project/mozilla/crash-ping-ingest/ci
    date-tasks:
      cron-days: 7
      action-manual: true
      index: "mozilla.v2.crash-ping-ingest.by-date.{date}.processed"
      env: PING_SUBMISSION_DATE
    run:
      using: run-task
      cache-dotcache: true
      cwd: '{checkout}'
      command:
        - bash
        - -euo
        - pipefail
        - -c
        - |
          SECRETS=$(curl http://taskcluster/secrets/v1/secret/project/mozilla/crash-ping-ingest/ci)
          export REDASH_API_KEY=$(echo $SECRETS | jq -r .secret.redash_api_key)
          export GOOGLE_APPLICATION_CREDENTIALS=credentials.json
          echo $SECRETS | jq -r .secret.google_application_credentials > $GOOGLE_APPLICATION_CREDENTIALS

          export RUST_LOG=info

          OUTPUT=processed-pings.jsonl

          # Configure and run the ingester. We also pass some worker-specific configuration on the command-line.
          ./date_version_config.py ${PING_SUBMISSION_DATE:-} | ingester --stdin --no-progress --output-file $OUTPUT "cache.size_limit_gb=50"

          # Upload to bigquery
          ./upload.py --production $OUTPUT
